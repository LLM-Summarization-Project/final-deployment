version: "3.9"

services:
  db:
    image: postgres:16
    container_name: db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER:-app}
      POSTGRES_PASSWORD: ${DB_PASS:-app}
      POSTGRES_DB: ${DB_NAME:-app}
    ports:
      - "5432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d
      - ./db/dumps:/dumps

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
      - ./entrypoint.sh:/entrypoint.sh:ro
    env_file: .env
    entrypoint: ["/bin/sh", "/entrypoint.sh"]

  redis:
    image: redis:7
    ports: ["6379:6379"]

  summarize:
    image: ghcr.io/${ORG}/${SUMMARIZE_REPO}:${TAG:-latest}
    depends_on: [db, ollama, redis]
    container_name: summarize
    restart: unless-stopped
    env_file: .env
    environment:
      # DATABASE_URL: postgres://${DB_USER:-app}:${DB_PASS:-app}@db:5432/${DB_NAME:-app}
      # PORT: 3000
      OLLAMA_API: ${OLLAMA_API}
      OLLAMA_MODEL: ${OLLAMA_MODEL}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
    command: ["node","dist/src/main.js"]
    ports: ["8081:8081"]
    volumes:
      - ./outputs:/app/outputs
    # expose:
    #   - "3000"

  summary_worker:
    image: ghcr.io/${ORG}/${SUMMARIZE_REPO}:${TAG:-latest}
    depends_on: [db, ollama, redis]
    container_name: summary_worker
    restart: unless-stopped
    env_file: .env
    environment:
      # DATABASE_URL: postgres://${DB_USER:-app}:${DB_PASS:-app}@db:5432/${DB_NAME:-app}
      # PORT: 3000
      OLLAMA_API: ${OLLAMA_API}
      OLLAMA_MODEL: ${OLLAMA_MODEL}
      REDIS_HOST: redis
      REDIS_PORT: "6379"
    command: ["node","dist/src/worker/index.js"]
    volumes:
      - ./outputs:/app/outputs
    # expose:
    #   - "3000"

  # Hypertext Backend (LLM processing service)
  hypertext-backend:
    image: ghcr.io/${ORG}/${HYPERTEXT_REPO:-hypertext_backend}:${TAG:-latest}
    depends_on: [db, ollama]
    container_name: hypertext-backend
    restart: unless-stopped
    env_file: .env
    environment:
      DATABASE_URL: ${DATABASE_URL}
      OLLAMA_API: ${OLLAMA_API}
      OLLAMA_MODEL: ${OLLAMA_MODEL}
      PORT: 3002
    ports:
      - "3002:3002"

  ontology:
    image: ghcr.io/${ORG}/${ONTO_REPO}:${TAG:-latest}
    # depends_on: [db]
    depends_on: [db, hypertext-backend]
    container_name: ontology
    restart: unless-stopped
    env_file: .env
    environment:
      DATABASE_URL: ${DATABASE_URL}
      HYPERTEXT_API_URL: http://hypertext-backend:3002
      PORT: 3000
    ports:
      - "3001:3000"
  auth-service:
      image: ghcr.io/${ORG}/${AUTH_REPO}:${TAG:-latest}
      container_name: auth-service
      restart: unless-stopped
      depends_on:
        - db
      environment:
        DATABASE_URL: ${DATABASE_URL}
        JWT_SECRET: ${JWT_SECRET}
        PORT: 4000
      ports:
        - "4005:4000"
        


  # proxy:
  #     image: nginx:alpine
  #     container_name: proxy
  #     depends_on: [summarize, ontology]
  #     restart: unless-stopped
  #     ports:
  #       - "80:80"
  #     volumes:
  #       - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro

  # frontend:
  #   image: ghcr.io/${ORG}/${FRONTEND_REPO}:${TAG:-latest}
  #   depends_on: [proxy]
  #   container_name: frontend
  #   restart: unless-stopped
  #   env_file: .env
  #   command: ["npm", "start"]
  #   ports:
  #     - "8080:8080"

volumes:
  db_data:
  ollama:
